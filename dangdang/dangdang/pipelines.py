# -*- coding: utf-8 -*-# Define your item pipelines here## Don't forget to add your pipeline to the ITEM_PIPELINES setting# See: https://doc.scrapy.org/en/latest/topics/item-pipeline.htmlimport pymysqlfrom scrapy import Requestfrom scrapy.pipelines.images import ImagesPipelinefrom scrapy.exceptions import DropItemclass DangdangPipeline(object):    def process_item(self, item, spider):        return itemclass MysqlPipeline(object):    def __init__(self,host,user,password,database,port):        self.host = host        self.user = user        self.password = password        self.database = database        self.port = port    @classmethod    def from_crawler(cls,crawler):        return cls(            host = crawler.settings.get("MYSQL_HOST"),            user = crawler.settings.get("MYSQL_USER"),            password = crawler.settings.get("MYSQL_PASS"),            database = crawler.settings.get("MYSQL_DATABASE"),            port = crawler.settings.get("MYSQL_PORT"),        )    def open_spider(self, spider):        '''负责连接数据库'''        self.db = pymysql.connect(self.host,self.user,self.password,self.database,charset="utf8",port=self.port)        self.cursor = self.db.cursor()            def process_item(self, item, spider):        '''执行数据表的写入操作'''        sql = "insert into pybook(name,author,pre_price,now_price,publish,pic,detail) values('%s','%s','%s','%s','%s','%s','%s')"%(str(item['name']),str(item['author']),str(item['pre_price']),str(item['now_price']),str(item['publish']),str(item['pic']),str(item['detail']))        self.cursor.execute(sql)        self.db.commit()        return item    def close_spider(self, spider):        '''关闭连接数据库'''        self.db.close()class ImagePipeline(ImagesPipeline):    '''自定义图片存储类'''    def get_media_requests(self, item, info):        '''通过抓取的item对象获取图片信息，并创建Request请求对象添加调度队列，等待调度执行下载'''        yield Request(item['pic'])    def file_path(self,request,response=None,info=None):        '''返回图片下载后保存的名称，没有此方法Scrapy则自动给一个唯一值作为图片名称'''        url = request.url        file_name = url.split("/")[-1]        return file_name    def item_completed(self, results, item, info):        ''' 下载完成后的处理方法'''        image_paths = [x['path'] for ok, x in results if ok]        if not image_paths:            raise DropItem("Item contains no images")        #item['image_paths'] = image_paths        return item